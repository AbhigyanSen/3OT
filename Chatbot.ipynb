{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Importing Libraries and Corpus**"
      ],
      "metadata": {
        "id": "mVP4u3yoBB4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import sklearn\n",
        "import string\n",
        "import random"
      ],
      "metadata": {
        "id": "YdW8BUHY1Wcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **For Response**"
      ],
      "metadata": {
        "id": "bouqIgq_CLPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "FPaTqhhu1oCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Avoiding Warnings"
      ],
      "metadata": {
        "id": "OAGxFOphBMxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "n1fIAdEZ1Yf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Importing and Reading the Corpus**"
      ],
      "metadata": {
        "id": "qK4y3a86BIRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "File = open('INFORMATION.txt', 'r', errors = 'ignore')\n",
        "RawDocument = File.read()\n",
        "RawDocument = RawDocument.lower()\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "#SentenceTokens = nltk.sent_tokenize(RawDocument)\n",
        "#WordTokens = nltk.word_tokenize(RawDocument)\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk7-1hIo1bRt",
        "outputId": "a4b6bb2d-d990-4c42-8501-f486d4f1869e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lexical Analysis**"
      ],
      "metadata": {
        "id": "gIiTG1MAASwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Converting the Corpus in a list of Sentences**"
      ],
      "metadata": {
        "id": "Ugnn2g74AVl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SentenceTokens = nltk.sent_tokenize(RawDocument)\n",
        "\n",
        "#Demo: Printing 02 Sentence Tokens\n",
        "SentenceTokens[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMkMddkM1dll",
        "outputId": "a538f2f1-41fe-4792-a81c-228b0cebed1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sony history\\nin 1946, tokyo tsushin kogyo k.k.',\n",
              " '(tokyo telecommunications engineering corporation, the predecessor of sony group corporation) started as a small company with capital of just 190,000 yen and approximately 20 employees.']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Converting the Corpus in a list of Words**"
      ],
      "metadata": {
        "id": "W8H45lw4AbVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WordTokens = nltk.word_tokenize(RawDocument)\n",
        "\n",
        "#Demo: Printing 02 Word Tokens\n",
        "WordTokens[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yanyiU971gOO",
        "outputId": "93cb49f5-ee14-44ae-96df-d7ff1eba0cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sony', 'history']"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Semantic Analysis** \n",
        "\n",
        "### **Text Preprocessing** "
      ],
      "metadata": {
        "id": "UnuezqE5AAXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Grouping similar words and alloting one word for the same\n",
        "Lemmer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def LemTokens(Tokens):\n",
        "    return [Lemmer.lemmatize(Token) for Token in Tokens]\n",
        "\n",
        "RemovePD = dict((ord(Punctuation), None) for Punctuation in string.punctuation)\n",
        "def LemNormalize(Text):\n",
        "    return LemTokens(nltk.word_tokenize(Text.lower().translate(RemovePD)))"
      ],
      "metadata": {
        "id": "7XaxBa521iZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Greeting the Customer**"
      ],
      "metadata": {
        "id": "-nwLkwOG_yUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CustomerInputs = (\"hello\", \"hi\", \"greetings\", \"hola\", \"sup\", \"what's up\", \"hey\",)\n",
        "BotResponses = [\"Hi\", \"Hey\", \"Hi There\", \"Hello\", \"Hey There\"]\n",
        "def Greet(Sentence):\n",
        "    for Word in Sentence.split():\n",
        "        if Word.lower() in CustomerInputs:\n",
        "            return random.choice(BotResponses)"
      ],
      "metadata": {
        "id": "XfT5HgNb1ldu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Response Generation**"
      ],
      "metadata": {
        "id": "gv8SLYax_ZL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Response(CustomerResponse):\n",
        "    BotRespond = ''\n",
        "    \n",
        "    #Dealing with the most frequent words and storing it in Matrix form\n",
        "    Vectorizer = TfidfVectorizer(tokenizer = LemNormalize, stop_words = 'english')\n",
        "    TfidfFit = Vectorizer.fit_transform(SentenceTokens)\n",
        "    vals = cosine_similarity(TfidfFit[-1], TfidfFit)\n",
        "    idx = vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    RequiredTfidfFit = flat[-2]\n",
        "    if(RequiredTfidfFit == 0):\n",
        "        BotRespond = BotRespond+\"My apologies. Please Try Something Else\"\n",
        "        return BotRespond\n",
        "    else:\n",
        "        BotRespond = BotRespond+SentenceTokens[idx]\n",
        "        return BotRespond"
      ],
      "metadata": {
        "id": "mglzfm501qV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Terminating Condition**"
      ],
      "metadata": {
        "id": "0r7Q97Z-_Mk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flag = True\n",
        "print(\"30T: Respond with 'Bye' to Exit Anytime.\")\n",
        "print(\"30T: Hello! Welcome to Sony Electronics. Hope you're having a Nice Day.\")\n",
        "print(\"30T: I am 301, How May I Help You?\")\n",
        "while(flag == True):\n",
        "    print()\n",
        "    CustomerResponse = input(\"You: \")\n",
        "    CustomerResponse = CustomerResponse.lower()\n",
        "\n",
        "    #Terminating Condition\n",
        "    if(CustomerResponse != 'bye'):\n",
        "        if(CustomerResponse == 'thanks' or CustomerResponse == 'thank you'):\n",
        "            flag == False\n",
        "            print(\"30T: You are Welcome!\")\n",
        "        else:\n",
        "            if(Greet(CustomerResponse) != None):\n",
        "                print(\"30T: \"+Greet(CustomerResponse))\n",
        "            else:\n",
        "                SentenceTokens.append(CustomerResponse)\n",
        "                FinalWords = list(set(WordTokens))\n",
        "                print(\"30T: \", end = \"\")\n",
        "                print(Response(CustomerResponse))\n",
        "                SentenceTokens.remove(CustomerResponse)\n",
        "    else:\n",
        "        flag = False\n",
        "        print(\"30T: Goodbye! Visit Again.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQwmcDqb1r7n",
        "outputId": "5b9be00f-0f25-4495-c67d-41a3e569c0de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30T: Respond with 'Bye' to Exit Anytime.\n",
            "30T: Hello! Welcome to Sony Electronics. Hope you're having a Nice Day.\n",
            "30T: I am 301, How May I Help You?\n",
            "\n",
            "You: hi\n",
            "30T: Hey\n",
            "\n",
            "You: GREETINGS\n",
            "30T: Hi There\n",
            "\n",
            "You: sup\n",
            "30T: Hi There\n",
            "\n",
            "You: Hello\n",
            "30T: Hi There\n",
            "\n",
            "You: thanks\n",
            "30T: You are Welcome!\n",
            "\n",
            "You: bye\n",
            "30T: Goodbye! Visit Again.\n"
          ]
        }
      ]
    }
  ]
}